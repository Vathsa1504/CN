{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "exp-1"
      ],
      "metadata": {
        "id": "JMUER1w_meAI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im6zppfCkbLp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Jept0yxtmkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lu2f7vlotmiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCqaqr7MtmgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWVc65dBtmbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp-2"
      ],
      "metadata": {
        "id": "ZNJjUZiLmlHk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tamu1YzJmj1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qC8_sscttlj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ro9OzX9btle2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_IG9XPZstlUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPjbxSuRtlRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp-3"
      ],
      "metadata": {
        "id": "KX2YVj5Pmog7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oEBfk8pnmntx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2IV6tsItk9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C_ffNENNtk3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLjRVOHetk1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b31FRycLtkzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp-4"
      ],
      "metadata": {
        "id": "7eOpTgmkmsSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers -U"
      ],
      "metadata": {
        "id": "WuulTu6fmrHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "glove_input_file = r\"C:\\Users\\student\\Desktop\\Generative AI\\glove.6B\\glove.6B.100d.\n",
        "word2vec_output_file = r\"C:\\Users\\student\\Desktop\\Generative AI\\glove.6B\\glove.6B.1\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
        "print(model.most_similar(\"king\"))"
      ],
      "metadata": {
        "id": "AI7NbvsItkfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install --upgrade langchain"
      ],
      "metadata": {
        "id": "e_9DeLdVtkWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-core"
      ],
      "metadata": {
        "id": "sa00AqdptkT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install langchain-community"
      ],
      "metadata": {
        "id": "vrIDb9GYtkRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "glove_input_file = r\"C:\\Users\\student\\Desktop\\Generative AI\\glove.6B\\glove.6B.100d.\n",
        "word2vec_output_file = r\"C:\\Users\\student\\Desktop\\Generative AI\\glove.6B\\glove.6B.1\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
        "print(model.most_similar(\"king\"))"
      ],
      "metadata": {
        "id": "XqDuTcUAkjZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_prompt = \"Explain the importance of vaccinations in healthcare\"\n",
        "key_terms = [\"vaccinations\",\"healthcare\"]\n",
        "similar_terms = []\n",
        "for term in key_terms:\n",
        "if term in model.key_to_index:\n",
        "similar_terms.extend({word for word, _ in model.most_similar(term, topn=3)})\n",
        "if similar_terms:\n",
        "enriched_prompt = f\"{original_prompt} consider aspects like: {', '.join(similar_\n",
        "else:\n",
        "enriched_prompt = original_prompt\n",
        "print(\"original_prompt:\",original_prompt)\n",
        "print(\"Enriched_prompt:\",enriched_prompt)"
      ],
      "metadata": {
        "id": "Oaqk0WbQkjIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "GOOGLE_API_KEY= os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your google API key: \") #API key - AizaSyCFuGECj03qtpuzgn0P7tFlBaQYk8APLnw"
      ],
      "metadata": {
        "id": "XZlqgvEEkvc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "model=\"gemini-2.0-flash-exp\",\n",
        "temperature=0,\n",
        "api_key=GOOGLE_API_KEY,\n",
        "max_tokens=256,\n",
        "timeout=None,\n",
        "max_retires=2,\n",
        ")"
      ],
      "metadata": {
        "id": "yOTUPGxDk3MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Hi\")"
      ],
      "metadata": {
        "id": "T-_34UGAk8wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(original_prompt).content)"
      ],
      "metadata": {
        "id": "GTSlbgdwk88T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp-5"
      ],
      "metadata": {
        "id": "QZ0B5Xi2muR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api import random\n",
        "# Step 1: Load pre-trained Word2Vec embeddings\n",
        "print(\"Loading pre-trained Word2Vec embeddings...\")\n",
        "word_vectors = api.load(\"word2vec-google-news-300\") # Load Google's Word2Vec model\n",
        "# Step 2: Function to retrieve similar words\n",
        "def similar_words(seed_word, top_n=5): try:\n",
        "similar_words = word_vectors.most_similar(seed_word, topn=top_n)\n",
        "return [word for word, _ in similar_words] except KeyError:\n",
        "print(f\"'{seed_word}' is not in the vocabulary. Please try another word.\") return []\n",
        "    # Step 3: Function to construct a paragraph\n",
        "def construct_paragraph(seed_word, similar_words): sentences = [\n",
        "        f\"Once upon a time, there was a {seed_word}.\",\n",
        "        f\"The {seed_word} was known for its connection to {similar_words[0]} and {similar_words[1]}.\",\n",
        "        f\"One day, the {seed_word} encountered a {similar_words[2]} and they became great friends.\",\n",
        "        f\"Together, they explored the world of {similar_words[3]} and discovered the wonders of {similar_words[4]}.\",\n",
        "        f\"In the end, the {seed_word} realized that life is full of surprises and adventures.\"\n",
        "]\n",
        "return \" \".join(sentences)\n",
        "# Step 4: Main program\n",
        "def main(): # Take a seed word as input\n",
        "seed_word = input(\"Enter a seed word: \").strip().lower() # Retrieve similar words similar_word = similar_words(seed_word)\n",
        "if not similar_word:\n",
        "return\n",
        "print(f\"\\nSimilar words to '{seed_word}': {', '.join(similar_word)}\") # Construct and display a paragraph paragraph = construct_paragraph(seed_word, similar_word)\n",
        "print(\"\\nHere's a short paragraph/story:\\n\")\n",
        "print(paragraph)\n",
        "main()"
      ],
      "metadata": {
        "id": "mCoFgrjDmz4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp-6"
      ],
      "metadata": {
        "id": "lEqp2qTjm2mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "# Load the sentiment analysis pipeline with a specific model and revision\n",
        "sentiment_analyzer = pipeline(\n",
        "task=\"sentiment-analysis\",\n",
        "model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\" # Model name\n",
        ")\n",
        "def analyze_sentiment(text):\n",
        "\"\"\"\n",
        "Analyze the sentiment of the given text using the pre-trained model.\n",
        ":param text: The input text to analyze.\n",
        ":return: The sentiment analysis result.\n",
        "\"\"\"\n",
        "result = sentiment_analyzer(text)\n",
        "return result\n",
        "def main():\n",
        "sentences = [\n",
        "\"I love this product! It's amazing.\",\n",
        "\"The service was terrible and I'm very disappointed.\",\n",
        "\"The movie was okay, not great but not bad either.\",\n",
        "\"This is the best day of my life!\",\n",
        "\"I feel so frustrated with this situation.\"\n",
        "]\n",
        "# Analyze the sentiment of each sentence\n",
        "for sentence in sentences:\n",
        "sentiment_result = analyze_sentiment(sentence)\n",
        "print(f\"Sentence: {sentence}\")\n",
        "print(f\"Sentiment: {sentiment_result[0]['label']} (confidence:{sentiment_result[0]['score']:.4f})\")\n",
        "print(\"-\" * 60)\n",
        "main() # Call the main function to execute the code"
      ],
      "metadata": {
        "id": "_JOLt1g9m4FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp-7"
      ],
      "metadata": {
        "id": "mybysYyLm4ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "# Specify the model and revision explicitly\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "def summarize_text(text, max_length=100, min_length=30, do_sample=False):\n",
        "\"\"\"\n",
        "Summarize the input text using the pre-trained model.\n",
        "Args:\n",
        "text (str): The input text to summarize.\n",
        "max_length (int): The maximum length of the summary.\n",
        "min_length (int): The minimum length of the summary.\n",
        "do_sample (bool): Whether or not to use sampling; use greedy decoding otherwise.\n",
        "Returns:\n",
        "str: The summarized text.\n",
        "\"\"\"\n",
        "# Summarize the text\n",
        "summary = summarizer(text, max_length=max_length, min_length=min_length,do_sample=do_sample)\n",
        "# Extract the summarized text from the output\n",
        "summarized_text = summary[0]['summary_text']\n",
        "return summarized_text\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "# Input passage\n",
        "passage = \"\"\"\n",
        "The Hugging Face Transformers library provides an easy-to-use interface for working\n",
        "with pre-trained models for various NLP tasks, including summarization.\n",
        "Summarization is the task of reducing a long text into a shorter version while preserving the key information.\n",
        "This can be particularly useful for quickly understanding the main points of lengthy documents, articles, or re\n",
        "The library supports several pre-trained models that can be used out-of-the-box forsummarization tasks.\n",
        "\"\"\"\n",
        "# Get the summarized text\n",
        "summarized_text = summarize_text(passage)\n",
        "# Print the summarized text\n",
        "print(\"Original Text:\\n\"\n",
        ", passage)\n",
        "print(\"\\nSummarized Text:\\n\"\n",
        ", summarized_text)"
      ],
      "metadata": {
        "id": "lzaSVMhdm7S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp-8"
      ],
      "metadata": {
        "id": "RNDWebDsm8ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-cohere\n",
        "!pip install langchain langchain-cohere langchain-community\n",
        "!pip install gdown\n",
        "!pip install gdown"
      ],
      "metadata": {
        "id": "JLkKIfMOm-DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "if not os.environ.get(\"COHERE_API_KEY\"):\n",
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter API key for Cohere: \") #API key - GxtsWQl3sQe15OLtt5JxgT5uVskwxiz6AMUYED9y\n",
        "from langchain_cohere import ChatCohere\n",
        "model = ChatCohere(model=\"command-r7b-12-2024\")"
      ],
      "metadata": {
        "id": "opr-yKhKqKzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_template(\"Tell me a quote on the {topic}\")\n",
        "chain = prompt | model\n",
        "chain.invoke({\"topic\": \"AI\"}).content"
      ],
      "metadata": {
        "id": "cML59yVCqKr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1BPgmF8od-gvK0GeDyaeAwCrSGpgvwXFN\"\n",
        "file_path = \"ai_agents_info.txt\"\n",
        "\n",
        "gdown.download(f\"https://drive.google.com/uc?export=download&id={file_id}\", file_path, quiet=False)\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "document_text = file.read()\n",
        "print(document_text)"
      ],
      "metadata": {
        "id": "jjJCq7TuqKkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_template(\"Extract and list the types of AI agents as bullet points from the following.\")\n",
        "chain = prompt | model\n",
        "print(chain.invoke({\"document_text\": document_text}).content)\n"
      ],
      "metadata": {
        "id": "8SbUgA9yqKcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp-9"
      ],
      "metadata": {
        "id": "p2xKQi5vm-la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet wikipedia"
      ],
      "metadata": {
        "id": "cBa6CfJLm_0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate # For creating prompt templates\n",
        "from langchain.chains import LLMChain # For creating chains that link LLMs and prompts\n",
        "from pydantic import BaseModel # For defining data schemas\n",
        "# Define Pydantic schema for the desired output\n",
        "class InstitutionDetails(BaseModel):\n",
        "\"\"\"\n",
        "Pydantic model to structure the output data for institution details.\n",
        "\"\"\"\n",
        "founder: str\n",
        "founded: str\n",
        "branches: int\n",
        "employees: int\n",
        "summary: str"
      ],
      "metadata": {
        "id": "JFh9KjXfo0z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "Given the name of an institution, extract the following details from Wikipedia:\n",
        "1. Founder of the institution\n",
        "2. When it was founded\n",
        "3. Current branches of the institution\n",
        "4. How many employees work in it\n",
        "5. A 4-line brief summary of the institution\n",
        "Institution: {institution_name}\n",
        "\"\"\"\n",
        "import getpass\n",
        "import os\n",
        "if not os.environ.get(\"COHERE_API_KEY\"):\n",
        "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter API key for Cohere: \") #API key - GxtsWQl3sQe15OLtt5JxgT5uVskwxiz6AMUYED9y\n",
        "from langchain_cohere import ChatCohere\n",
        "model = ChatCohere(model=\"command-r7b-12-2024\")"
      ],
      "metadata": {
        "id": "9dMZLvZeo0pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(input_variables=[\"institution_name\"], template=prompt_template)\n",
        "def fetch_institution_details(institution_name: str):\n",
        "\"\"\"\n",
        "Fetches institution details using the Langchain chain and GPT-3 model.\n",
        "Args:\n",
        "institution_name (str): The name of the institution to fetch details for.\n",
        "Returns:\n",
        "str: The result from the LLMChain run, containing institution details.\n",
        "\"\"\"\n",
        "result = chain.run(institution_name=institution_name)\n",
        "return result\n",
        "\n",
        "institution_name = input(\"Enter the institution name: \")\n",
        "\n",
        "institution_details = fetch_institution_details(institution_name)\n",
        "\n",
        "print(institution_details)"
      ],
      "metadata": {
        "id": "TDHihEzUo0bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp-10"
      ],
      "metadata": {
        "id": "zBN7k43pnAWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "KxxhN_CvowxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
        "import numpy as np\n",
        "from pypdf import PdfReader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "hpEUb_b4nBxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf"
      ],
      "metadata": {
        "id": "tGVb4PvenkX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader # Import PdfReader from the pypdf library\n",
        "reader = PdfReader(\"/home/dhanu/Desktop/Generative AI/BNS(IPC).pdf\") # Create a PdfReader object to read the PDF fi\n",
        "pdf_texts = [p.extract_text().strip() for p in reader.pages] # Extract text from each page of the PDF, strip whites\n",
        "# Filter out empty strings from the list of extracted texts\n",
        "pdf_texts = [text for text in pdf_texts if text]\n",
        "print(pdf_texts[0])"
      ],
      "metadata": {
        "id": "z4Do6WSZnlTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter # Import\n",
        "character_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=20\n",
        ")\n",
        "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
        "print(character_split_texts[10])\n",
        "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
      ],
      "metadata": {
        "id": "t0_zk1Yxnrpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "import os\n",
        "inference_api_key = getpass()\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = inference_api_key\n",
        "inference_api_key\n",
        "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "embedding_function = HuggingFaceInferenceAPIEmbeddings(\n",
        "api_key=inference_api_key, # API key - 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\n",
        "model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
        ")\n",
        "from langchain_community.vectorstores import FAISS\n",
        "db = FAISS.from_texts(character_split_texts, embedding_function)\n",
        "print(db.index.ntotal)"
      ],
      "metadata": {
        "id": "-Set7p9ToBfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-gpu"
      ],
      "metadata": {
        "id": "tY-DJsqJoP9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does BNS Section 72 talks about ?\" # Define the query string to search for in the vector database\n",
        "retrieved_documents = db.similarity_search(query)\n",
        "retrieved_documents"
      ],
      "metadata": {
        "id": "jFQBaD7KoQqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}